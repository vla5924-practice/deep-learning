# %% [markdown]
# # –ì–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ. –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ2
# 
# **–¶–µ–ª—å:** —Ä–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å –∏ –æ–±—É—á–∏—Ç—å —Å–≤–µ—Ä—Ç–æ—á–Ω—É—é –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å –¥–ª—è –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º  PyTorch. 
# 
# **–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã:**
# 
# 1. –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É Jupyter Notebook:
#     - –ó–∞–≥—Ä—É–∑–∏—Ç—å –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–∞–Ω–Ω—ã–µ (–Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –æ–±–µ—Å–ø–µ—á–∏—Ç—å –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—é –∏–∑–±—Ä–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –º–µ—Ç–æ–∫ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –∑–∞–≥—Ä—É–∑–∫–∏ –∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π).
#     - –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç—å —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞ PyTorch.
#     - –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã, —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è –∏ —Ä–∞–∑–º–µ—Ä–∞ –ø–∞—á–∫–∏ (batch size)).
#     - –í—ã–≤–µ—Å—Ç–∏ –æ—à–∏–±–∫—É –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏ —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ –æ–∫–æ–Ω—á–∞–Ω–∏–∏ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏.
#     - –í—ã–≤–µ—Å—Ç–∏ –æ—à–∏–±–∫—É –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö –∏ –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫ –æ—à–∏–±–∫–∏ –æ–±—É—á–µ–Ω–∏—è –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è.
# 
# 2. –í—ã–±–æ—Ä –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã:
#     - –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å ***—Å–≤–µ—Ä—Ç–æ—á–Ω—ã–µ*** –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π
#     - –†–∞–∑—Ä–µ—à–∞–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫ –≥–æ—Ç–æ–≤—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, VGG, ResNet –∏ —Ç–¥), —Ç–∞–∫ –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Å—Ç—É–¥–µ–Ω—Ç–æ–º —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ. 
#     - –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —Å –Ω—É–ª—è –≤ PyTorch, –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≥–æ—Ç–æ–≤—ã—Ö –º–æ–¥—É–ª–µ–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, import Resnet –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º–æ).

# %%
from datetime import datetime
import os
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Subset, DataLoader
from torch.utils.tensorboard import SummaryWriter
import torchvision
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import matplotlib.pyplot as plt
import numpy as np
from time import time

# %%
# –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
RANDOM_SEED = 5924
BATCH_SIZE = 256
LEARNING_RATE = 0.1
LEARNING_RATE_MIN = 0.0001
SCHEDULING_FACTOR = 0.8
SCHEDULING_PATIENCE = 3
NUM_EPOCHS = 30

# %% [markdown]
# ## –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
# 
# –í –∫–∞—á–µ—Å—Ç–≤–µ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–∞—Ç–∞—Å–µ—Ç Cifar-10 —Å —Å–∞–π—Ç–∞ https://www.cs.toronto.edu/~kriz/cifar.html

# %% [markdown]
# ### –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
# 
# –î–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–≥—Ä—É–∑—á–∏–∫–∞ –±—ã–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –æ–±—É—á–∞—é—â–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã —Å —Å–∞–π—Ç–∞ https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html

# %%
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
])
torch.manual_seed(RANDOM_SEED)
print("Using random seed", RANDOM_SEED)
train_dataset = datasets.CIFAR10(root="/work/cifar", train=True, download=True, transform=transform)
train_dataset = Subset(train_dataset, torch.randperm(len(train_dataset)))
test_dataset = datasets.CIFAR10(root="/work/cifar", train=False, download=True, transform=transform)
test_dataset = Subset(test_dataset, torch.randperm(len(test_dataset)))
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)
classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
print("Train datset size:", len(train_dataset))
print("Test datset size:", len(test_dataset))

# %% [markdown]
# ### –í–∏–∑—É–∞–ª—å–Ω–∞—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è
# 
# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –≤—ã–≤–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –ø–µ—Ä–≤—ã—Ö –≤–æ—Å—å–º–∏.

# %%
def imshow(img):
    img = (img / 2 + 0.5).numpy() # unnormalize
    plt.imshow(np.transpose(img, (1, 2, 0)))
    plt.axis("off")
    plt.show()

dataiter = iter(train_loader)
images, labels = next(dataiter)
imshow(torchvision.utils.make_grid(images[:8]))
print(' '.join("%5s" % classes[labels[j]] for j in range(8)))

# %% [markdown]
# ## –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å MobileNet
# 
# > Howard A.G., et al. MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications (2017) https://arxiv.org/pdf/1704.04861.pdf
# 
# ### –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–ª–æ—ë–≤
# 
# | Type / Stride | Filter Shape        | Input Size     |
# |---------------|---------------------|----------------|
# | Conv / s2     | 3 √ó 3 √ó 3 √ó 32      | 224 √ó 224 √ó 3  |
# | Conv dw / s1  | 3 √ó 3 √ó 32 dw       | 112 √ó 112 √ó 32 |
# | Conv / s1     | 1 √ó 1 √ó 32 √ó 64     | 112 √ó 112 √ó 32 |
# | Conv dw / s2  | 3 √ó 3 √ó 64 dw       | 112 √ó 112 √ó 64 |
# | Conv / s1     | 1 √ó 1 √ó 64 √ó 128    | 56 √ó 56 √ó 64   |
# | Conv dw / s1  | 3 √ó 3 √ó 128 dw      | 56 √ó 56 √ó 128  |
# | Conv / s1     | 1 √ó 1 √ó 128 √ó 128   | 56 √ó 56 √ó 128  |
# | Conv dw / s2  | 3 √ó 3 √ó 128 dw      | 56 √ó 56 √ó 128  |
# | Conv / s1     | 1 √ó 1 √ó 128 √ó 256   | 28 √ó 28 √ó 128  |
# | Conv dw / s1  | 3 √ó 3 √ó 256 dw      | 28 √ó 28 √ó 256  |
# | Conv / s1     | 1 √ó 1 √ó 256 √ó 256   | 28 √ó 28 √ó 256  |
# | Conv dw / s2  | 3 √ó 3 √ó 256 dw      | 28 √ó 28 √ó 256  |
# | Conv / s1     | 1 √ó 1 √ó 256 √ó 512   | 14 √ó 14 √ó 256  |
# | 5√ó {          |                     |                |
# | Conv dw / s1  | 3 √ó 3 √ó 512 dw      | 14 √ó 14 √ó 512  |
# | Conv / s1     | 1 √ó 1 √ó 512 √ó 512   | 14 √ó 14 √ó 512  |
# | }             |                     |                |
# | Conv dw / s2  | 3 √ó 3 √ó 512 dw      | 14 √ó 14 √ó 512  |
# | Conv / s1     | 1 √ó 1 √ó 512 √ó 1024  | 7 √ó 7 √ó 512    |
# | Conv dw / s2  | 3 √ó 3 √ó 1024 dw     | 7 √ó 7 √ó 1024   |
# | Conv / s1     | 1 √ó 1 √ó 1024 √ó 1024 | 7 √ó 7 √ó 1024   |
# | Avg Pool / s1 | Pool 7 √ó 7          | 7 √ó 7 √ó 1024   |
# | FC / s1       | 1024 √ó 1000         | 1 √ó 1 √ó 1024   |
# | Softmax / s1  | Classifier          | 1 √ó 1 √ó 1000   |
# 
# 
# –ù–∏–∂–µ –ø—Ä–∏–≤–µ–¥–µ–Ω—ã —Å—Ö–µ–º—ã –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –±–∞–∑–æ–≤—ã—Ö –±–ª–æ–∫–æ–≤ —Å–µ—Ç–∏:
# 1. –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫ —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π –ø–æ –ø–∞—á–∫–µ (`Conv`)
# 2. –°–≤–µ—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫, –ø–æ—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –Ω–∞ –æ—Ç–¥–µ–ª–∏–º–æ–π –ø–æ –≥–ª—É–±–∏–Ω–µ —Å–≤–µ—Ä—Ç–∫–µ (`Conv dw`)
# 
# ```
#      (1)                        (2)
# +-----------+          +-------------------+
# | Conv  3x3 |          | DepthwiseConv 3x3 |
# +-----------+          +-------------------+
#       |                          |
# +-----------+          +-------------------+
# | BatchNorm |          |     BatchNorm     |
# +-----------+          +-------------------+
#       |                          |
# +-----------+          +-------------------+
# |   ReLU    |          |       ReLU        |
# +-----------+          +-------------------+
#                                  |
#                        +-------------------+
#                        |     Conv 1x1      |
#                        +-------------------+
#                                  |
#                        +-------------------+
#                        |     BatchNorm     |
#                        +-------------------+
#                                  |
#                        +-------------------+
#                        |       ReLU        |
#                        +-------------------+
# ```

# %% [markdown]
# ### –†–µ–∞–ª–∏–∑–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é PyTorch
# 
# –ö–ª–∞—Å—Å `ConvBlock` –ø—Ä–∏–º–µ–Ω—è–µ—Ç –ø–∞—Ä—É —Å–ª–æ–µ–≤ `Conv` + `Conv dw`, –æ–ø–∏—Å–∞–Ω–Ω—ã–µ –≤—ã—à–µ. –≠—Ç–æ—Ç –∫–ª–∞—Å—Å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ —Ç–µ–ª–µ –º–µ—Ç–æ–¥–∞ `forward` –∫–ª–∞—Å—Å–∞ `MobileNet`, –∫–æ—Ç–æ—Ä—ã–π —Ä–µ–∞–ª–∏–∑—É–µ—Ç, —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ, –æ–¥–Ω–æ–∏–º–µ–Ω–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –Ω–µ–π—Ä–æ—Å–µ—Ç–∏.

# %%
class ConvBlock(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1):
        super().__init__()
        self.depthwise_conv = nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=stride, padding=1, groups=in_channels, bias=False)
        self.bn1 = nn.BatchNorm2d(in_channels)
        self.relu = nn.ReLU(inplace=True)
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)

    def forward(self, x: torch.Tensor):
        x = self.depthwise_conv(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.conv(x)
        x = self.bn2(x)
        x = self.relu(x)
        return x

class MobileNet(nn.Module):
    def __init__(self, num_classes, cache_weights=None):
        super().__init__()
        self.cache_weights = cache_weights or f"{self.__class__.__name__}_weights.pth"
        self.layers = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            ConvBlock(32, 64, stride=1),
            ConvBlock(64, 128, stride=2),
            ConvBlock(128, 128, stride=1),
            ConvBlock(128, 256, stride=2),
            ConvBlock(256, 256, stride=1),
            ConvBlock(256, 512, stride=2),
            *(ConvBlock(512, 512, stride=1) for _ in range(5)),
            ConvBlock(512, 1024, stride=2),
            ConvBlock(1024, 1024, stride=1),
            nn.AdaptiveAvgPool2d(1),
        )
        self.fc = nn.Linear(1024, num_classes)

    def forward(self, x: torch.Tensor):
        x = self.layers(x)
        x = x.view(x.size(0), -1) # last-dimension-wise flatten
        x = self.fc(x)
        return x

    def save(self):
        torch.save(self.state_dict(), self.cache_weights)

    def load(self):
        self.load_state_dict(torch.load(self.cache_weights, weights_only=True))

    def run_test(self, data_loader: DataLoader, compute_loss):
        correct = 0
        total = 0
        loss = 0.0
        device = next(self.parameters()).device
        with torch.no_grad():
            for images, labels in data_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = self(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
                loss += compute_loss(outputs, labels).item()
        loss /= len(data_loader)
        return correct, total, loss

# %% [markdown]
# ## –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
# 
# –í –∫–∞—á–µ—Å—Ç–≤–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –∫—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—è.
# 
# –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –±—É–¥–µ—Ç –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç—å —Å –ø–æ–º–æ—â—å—é –º–µ—Ç–æ–¥–∞ Adam (`torch.optim.Adam`). –í –ø—Ä–æ—Ü–µ—Å—Å–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ —Ç–∞–∫–∂–µ –ø—Ä–æ–≤–æ–¥–∏–ª–∏—Å—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ —Å–ø—É—Å–∫–∞ (`torch.optim.SGD`), –Ω–æ –æ–Ω –ø–æ–∫–∞–∑–∞–ª —Å–µ–±—è –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Ö—É–∂–µ.

# %%
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)

model = MobileNet(num_classes=len(classes), cache_weights="/work/lab2_weights.pth").to(device)
compute_loss = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode="min", factor=SCHEDULING_FACTOR, patience=SCHEDULING_PATIENCE, min_lr=LEARNING_RATE_MIN)

# %% [markdown]
# ### –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
# 
# –§—Ä–∞–≥–º–µ–Ω—Ç –∫–æ–¥–∞ `(*)` –≤—ã–ø–æ–ª–Ω—è–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–∏—Ö –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏ –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –ø—É—Ç–µ–º –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ.
# 
# –¢–∞–∫–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ä–µ–≥—É–ª—è—Ç–æ—Ä —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è `torch.optim.lr_scheduler.ReduceLROnPlateau`, –∫–æ—Ç–æ—Ä—ã–π —É–º–µ–Ω—å—à–∞–µ—Ç –µ–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–Ω–∞—á–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ.

# %%
log_dir = os.path.join(os.path.abspath(os.sep), "work", "lab2_tensorboard", datetime.now().strftime("%Y%m%d_%H%M%S"))
writer = SummaryWriter(log_dir)
write_parameters = {
    "RANDOM_SEED": RANDOM_SEED,
    "BATCH_SIZE": BATCH_SIZE,
    "LEARNING_RATE": LEARNING_RATE,
    "LEARNING_RATE_MIN": LEARNING_RATE_MIN,
    "SCHEDULING_FACTOR": SCHEDULING_FACTOR,
    "SCHEDULING_PATIENCE": SCHEDULING_PATIENCE,
    "NUM_EPOCHS": NUM_EPOCHS,
}
for name, value in write_parameters.items():
    writer.add_text(f"parameters/{name.lower().replace("_", " ")}", str(value), 0)

best_accuracy = 0.0
loss_stat = []
error_stat = []
accuracy_stat = []
total_start_time = time()

for epoch in range(NUM_EPOCHS):
    total_loss = 0.0
    correct = 0
    total = 0
    start_time = time()

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = compute_loss(outputs, labels)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
    
    loss = total_loss / len(train_loader)
    accuracy = correct / total
    error = 1 - accuracy
    end_time = time()
    loss_stat.append(loss)
    accuracy_stat.append(accuracy)
    error_stat.append(error)
    writer.add_scalar("loss/train", loss, epoch)
    writer.add_scalar("accuracy/train", accuracy, epoch)
    writer.add_scalar("error/train", error, epoch)
    print(f"‚åõ Epoch {epoch}: Elapsed {end_time - start_time:.2f} seconds, Loss {loss:.4f}, Accuracy {accuracy:.4f}, Error {error:.4f}")

    # (*)
    model.eval()
    test_correct, test_total, test_loss = model.run_test(test_loader, compute_loss)
    scheduler.step(test_loss)
    model.train()
    test_accuracy = test_correct / test_total
    writer.add_scalar("accuracy/test", test_accuracy, epoch)
    writer.add_scalar("loss/test", test_loss, epoch)
    accuracy_verdict = ""
    if test_accuracy > best_accuracy:
        best_accuracy = test_accuracy
        model.save()
        accuracy_verdict = ", this is the best accuracy so far üîÑÔ∏è"
    else:
        accuracy_verdict = f", which is less than the best accuracy {best_accuracy}"
    writer.add_scalar("best accuracy/test", best_accuracy, epoch)
    last_lr = scheduler.get_last_lr()[-1]
    writer.add_scalar("learning rate/train", last_lr, epoch)
    print(f"‚úÖ Epoch {epoch}: Learning rate {last_lr:.4f}, Test loss: {test_loss:.4f}, Test accuracy {test_accuracy:.4f}{accuracy_verdict}")

total_end_time = time()
print(f"Total training time: {total_end_time - total_start_time:.2f} seconds")
writer.close()

# %% [markdown]
# ### –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
# 
# –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è –ø—É—Ç–µ–º –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ.

# %%
model.load()
model.eval()
correct, total, _ = model.run_test(test_loader, compute_loss)
print(f"Test accuracy: {correct / total:.4f}")

# %% [markdown]
# –ù–∏–∂–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –≥—Ä–∞—Ñ–∏–∫–∏ –æ—à–∏–±–∫–∏ –æ–±—É—á–µ–Ω–∏—è, —Ç–æ—á–Ω–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è –∏ –∑–Ω–∞—á–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –æ—à–∏–±–∫–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —ç–ø–æ—Ö–∏.

# %%
_, plots = plt.subplots(1, 3, figsize=(20, 5))
plot_data = {"error": error_stat, "accuracy": accuracy_stat, "loss": loss_stat}
for i, (metric, stat) in enumerate(plot_data.items()):
    x = [i for i in range(NUM_EPOCHS)]
    plots[i].plot(x, stat, marker="o")
    plots[i].set_title(f"Training {metric}")
    plots[i].set_xlabel("epoch")
    plots[i].set_xticks(x)
    plots[i].set_ylabel(metric)
    plots[i].grid()
plt.tight_layout()
plt.show()
